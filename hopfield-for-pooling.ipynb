{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:04:02.710409400Z",
     "start_time": "2024-03-05T23:03:58.942308500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available for use with PyTorch: True\n",
      "Installed Python version:  3.8.18\n",
      "Installed PyTorch version: 2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "# Imports as always.\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from hflayers import Hopfield, HopfieldLayer, HopfieldPooling\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from data_handling import ISICDataset\n",
    "\n",
    "# Ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Beautification.\n",
    "sns.set_context('paper')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "print(f'CUDA is available for use with PyTorch: {torch.cuda.is_available()}')\n",
    "\n",
    "print(f'Installed Python version:  {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}')\n",
    "print(f'Installed PyTorch version: {torch.__version__}')\n",
    "\n",
    "# Helper function to send a tensor/model/etc. to the CPU/GPU accordingly.\n",
    "def to_device(x):\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cuda()\n",
    "    else:\n",
    "        return x.cpu()\n",
    "    \n",
    "# Helper function for closing figures.\n",
    "def close_figures():\n",
    "    while len(plt.get_fignums()) > 0:\n",
    "        plt.close()\n",
    "        \n",
    "# Get the current data and time as a string.\n",
    "date_string = datetime.now().strftime('%Y-%m-%d-(%H-%M-%S)')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hopfield as Pooling\n",
    "\n",
    "This notebook will look at `HopfieldPooling` as a direct substitute for `MaxPooling`. We'll be doing this for MNIST classification rather than ISIC segmentation; firstly to avoid any up-scaling complications (e.g. with unpooling), and secondly because fuck you.\n",
    "\n",
    "### From the continuous Hopfield paper\n",
    "\n",
    "The `HopfieldPooling` layer is designed for fixed pattern search, pooling operations, and memories like LSTMs or GRUs. The state (i.e. query) pattern is static, and may be learned during training.\n",
    "\n",
    "If only one static state pattern (i.e. query) exists, then this is de facto a pooling over the sequence. This static state pattern is considered a \"prototype pattern\" and consequently learned in the Hopfield pooling layer. Note that the pooling always operates over the *token* dimension  (i.e. the sequence length), not the embedding dimension.\n",
    "\n",
    "![Hopfield pooling diagram](./hopfield_pooling_diagram.png)\n",
    "\n",
    "```\n",
    "hopfield_pooling = HopfieldPooling(\n",
    "    input_size=4,       # Y\n",
    "    hidden_size=3,      # Q\n",
    "    scaling=beta,\n",
    "    quantity=2)         # No. state patterns\n",
    "\n",
    "# Stored_pattern and pattern_projection\n",
    "hopfield_pooling(Y)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c8379c4ffe4257d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Handling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f352ec3299cb252"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Pre-define a couple of transform functions to and from tensors and images.\n",
    "tensor_to_image = transforms.ToPILImage()\n",
    "image_to_tensor = transforms.ToTensor()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:04:16.772549400Z",
     "start_time": "2024-03-05T23:04:16.762034700Z"
    }
   },
   "id": "e71ea45621e65ff"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0, 1)])\n",
    "\n",
    "# Define the train dataset.\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/MNIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Define the test dataset.\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/MNIST',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Train-val split.\n",
    "train_idx, val_idx = train_test_split(list(range(len(train_dataset))), test_size=.2)\n",
    "train_subset = Subset(train_dataset, train_idx)\n",
    "val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "# Package into data loaders.\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_subset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:04:18.821846900Z",
     "start_time": "2024-03-05T23:04:18.615510Z"
    }
   },
   "id": "444ff1dbb16a8a45"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MNIST Classification Training Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f3917215f9f06ab"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:04:21.976385Z",
     "start_time": "2024-03-05T23:04:21.917708Z"
    }
   },
   "id": "e6e91139bf7942b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple CNN Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b79210f59b3e688"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class StandardCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StandardCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:04:25.225095700Z",
     "start_time": "2024-03-05T23:04:25.215994Z"
    }
   },
   "id": "1249e314ab6c873c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94f3578ed7a046d8b8d20a0907cf42c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0808, Accuracy: 11712/12000 (98%)\n",
      "Average loss: 0.0502, Accuracy: 11820/12000 (98%)\n",
      "Average loss: 0.0434, Accuracy: 11851/12000 (99%)\n",
      "Average loss: 0.0390, Accuracy: 11862/12000 (99%)\n",
      "Average loss: 0.0406, Accuracy: 11866/12000 (99%)\n"
     ]
    }
   ],
   "source": [
    "# Model, optimiser, and scheduler.\n",
    "standard_cnn_model = StandardCNN().to('cuda')\n",
    "optimiser = torch.optim.Adam(standard_cnn_model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimiser, step_size=1, gamma=.7)\n",
    "\n",
    "# Training.\n",
    "epochs = 5\n",
    "for epoch_idx in tqdm(range(1, epochs + 1), desc='Training'):\n",
    "    train(standard_cnn_model, 'cuda', train_dataloader, optimiser) \n",
    "    test(standard_cnn_model, 'cuda', val_dataloader)\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:07:20.319443200Z",
     "start_time": "2024-03-05T23:04:28.395613700Z"
    }
   },
   "id": "e65e05b8194bbd39"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Save model.\n",
    "torch.save(standard_cnn_model.state_dict(), f'./models/cnn/saves/{date_string}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:10:41.555161Z",
     "start_time": "2024-03-05T23:10:41.537640600Z"
    }
   },
   "id": "408b6d4e7c0c6878"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN with Learnable Hopfield Pooling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13dcc4f9263aed0d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_sinusoidal_encoding(n_tokens, token_length):\n",
    "    def get_position_angle_vector(i):\n",
    "        return [i / np.power(10000, 2 * (j // 2) / token_length) for j in range(token_length)]\n",
    "\n",
    "    table = np.array([get_position_angle_vector(i) for i in range(n_tokens)])\n",
    "    table[:, 0::2] = np.sin(table[:, 0::2])\n",
    "    table[:, 1::2] = np.cos(table[:, 1::2])\n",
    "\n",
    "    return torch.FloatTensor(table).unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:10:47.673939700Z",
     "start_time": "2024-03-05T23:10:47.663419300Z"
    }
   },
   "id": "b93d72b7e1a43bdd"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer: input shape torch.Size([16, 3, 64, 64]) -> output shape torch.Size([16, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "# Sequence-embedding network.\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, channels, embed_dim):\n",
    "        super().__init__()\n",
    "        self.image_size = int(image_size)\n",
    "        self.patch_size = int(patch_size)\n",
    "        self.channels = int(channels)\n",
    "        self.embed_dim = int(embed_dim)\n",
    "        \n",
    "        # Trainable linear projection for mapping dimension of patches.\n",
    "        self.W_E = nn.Parameter(torch.randn(self.patch_size * self.patch_size * self.channels, self.embed_dim))\n",
    "        \n",
    "        # Fixed sinusoidal positional embedding.\n",
    "        self.n_patches = self.image_size ** 2 // self.patch_size ** 2\n",
    "        self.PE = get_sinusoidal_encoding(n_tokens=self.n_patches, token_length=self.embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Patching.\n",
    "        patches = x.unfold(1, self.channels , self.channels).unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
    "        patches = patches.contiguous().view(patches.size(0), -1, self.channels  * self.patch_size * self.patch_size).float()\n",
    "        \n",
    "        # Patch embeddings.\n",
    "        patch_embeddings = torch.matmul(patches, self.W_E)\n",
    "        \n",
    "        # Position embeddings.\n",
    "        embeddings = patch_embeddings + self.PE\n",
    "        \n",
    "        # Transpose so that each column represents a patch embedding.\n",
    "        #embeddings = torch.transpose(embeddings, 1, 2)\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "# Shape check.\n",
    "channels, image_size, patch_size, embed_dim = 3, 64, 16, 768\n",
    "embedding_layer = Embedding(image_size, patch_size, channels, embed_dim)\n",
    "x = torch.randn(batch_size, channels, image_size, image_size)\n",
    "y = embedding_layer(x)\n",
    "print(f'Embedding layer: input shape {x.shape} -> output shape {y.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T23:10:51.493059200Z",
     "start_time": "2024-03-05T23:10:51.450801100Z"
    }
   },
   "id": "4d107e209c8737de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the Hopfield pooling substitute for Max pooling.\n",
    "class HopfieldImagePooling(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, channels, embed_dim):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.channels = channels\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Embedding layer.\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolution (batch_size, channels, image_size, image_size) -> Embedding (batch_size, n_patches, embed_dim).\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "546def7b0e5816ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
